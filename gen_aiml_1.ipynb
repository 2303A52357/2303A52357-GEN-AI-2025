{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# ASSIGNMENT - 01\n",
        "# GENERATIVE AI\n",
        "**2303A52357**\n",
        "\n",
        "**BATCH-33**\n",
        "\n"
      ],
      "metadata": {
        "id": "nJdXwNH3hjR5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**# Question-1.** (1 ponto) Write Python code from scratch to find error metrics of deep learning model. Actual\n",
        "values and deep learning model predicted values are shown in Table 1. Also compare the results\n",
        "with the outcomes of libraries\n",
        "YActual YP red\n",
        "20 20.5\n",
        "30 30.3\n",
        "40 40.2\n",
        "50 50.6\n",
        "60 60.7\n",
        "Tabela 1: YActual Vs. YP red"
      ],
      "metadata": {
        "id": "kZcOCS88hJvR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_squared_error(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mse = sum((y_true[i] - y_pred[i]) ** 2 for i in range(n)) / n\n",
        "    return mse\n",
        "\n",
        "def mean_absolute_error(y_true, y_pred):\n",
        "    n = len(y_true)\n",
        "    mae = sum(abs(y_true[i] - y_pred[i]) for i in range(n)) / n\n",
        "    return mae\n",
        "\n",
        "def root_mean_squared_error(y_true, y_pred):\n",
        "    mse = mean_squared_error(y_true, y_pred)\n",
        "    rmse = mse ** 0.5\n",
        "    return rmse\n",
        "\n",
        "y_true = [20,30,40,50,60]\n",
        "y_pred = [20.5,30.3,40.2,50.6,60.7]\n",
        "\n",
        "print(\"MSE:\", mean_squared_error(y_true, y_pred))\n",
        "print(\"MAE:\", mean_absolute_error(y_true, y_pred))\n",
        "print(\"RMSE:\", root_mean_squared_error(y_true, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dSxDwDySh0yY",
        "outputId": "33e7637a-80f4-4fc4-c186-b038124080bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE: 0.24600000000000147\n",
            "MAE: 0.4600000000000016\n",
            "RMSE: 0.49598387070549127\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Question-2**. (1 ponto) Write python code from scratch to find evaluation metrics of deep learning model.\n",
        "Actual values and deep learning model predicted values are shown in Table 2. Also compare the\n",
        "results with outcome of libraries\n",
        "YActual YP red\n",
        "0 0 1 1 2 0\n",
        "0 0 1 0 2 0\n",
        "0 1 1 2 2 1\n",
        "0 2 1 0 2 2\n",
        "0 2 1 2 2 2\n",
        "Tabela 2: YActual Vs. YP red\n",
        "• Expected Leaning Outcomes from this assignment related to python\n",
        "– Students are able to understand deep learning model metrics\n",
        "– Students are able to write code in python to find deep learning model metrics\n",
        "– Students are able to use python libraries to find deep learning model metrics\n"
      ],
      "metadata": {
        "id": "004m1F6lh6R4"
      }
    },
    {
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    c = sum(1 for i in range(len(y_true)) if y_true[i] == y_pred[i])\n",
        "    return c / len(y_true)\n",
        "\n",
        "def precision(y_true, y_pred, class_label):\n",
        "    true = sum(1 for i in range(len(y_true)) if y_true[i] == y_pred[i] == class_label)\n",
        "    predicted = sum(1 for i in range(len(y_true)) if y_pred[i] == class_label)\n",
        "    if predicted == 0:\n",
        "        return 0\n",
        "    return true / predicted\n",
        "\n",
        "def recall(y_true, y_pred, class_label):\n",
        "    true = sum(1 for i in range(len(y_true)) if y_true[i] == y_pred[i] == class_label)\n",
        "    actual = sum(1 for i in range(len(y_true)) if y_true[i] == class_label)\n",
        "    if actual == 0:\n",
        "        return 0\n",
        "    return true / actual\n",
        "\n",
        "def f1_score(precision, recall):\n",
        "    if precision + recall == 0:\n",
        "        return 0\n",
        "    return 2 * (precision * recall) / (precision + recall)\n",
        "\n",
        "y_true = [0, 0, 0, 0, 0]\n",
        "y_pred = [0, 0, 1, 2, 2]\n",
        "\n",
        "print(\"Accuracy:\", accuracy(y_true, y_pred))\n",
        "\n",
        "# Calculate precision, recall, and F1-score for class 0\n",
        "precision_class_0 = precision(y_true, y_pred, 0)  # Call the precision function with class_label=0\n",
        "recall_class_0 = recall(y_true, y_pred, 0)      # Call the recall function with class_label=0\n",
        "f1_class_0 = f1_score(precision_class_0, recall_class_0) # Calculate F1-score using the calculated precision and recall\n",
        "\n",
        "print(\"Precision :\", precision_class_0)\n",
        "print(\"Recall :\", recall_class_0)\n",
        "print(\"F1-Score :\", f1_class_0)"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "elwm399eizQ5",
        "outputId": "4d12942e-2d92-4ffd-a5db-ea2f5feb56b4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.4\n",
            "Precision : 1.0\n",
            "Recall : 0.4\n",
            "F1-Score : 0.5714285714285715\n"
          ]
        }
      ]
    }
  ]
}